{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection\n",
    "\n",
    "### Detecting vehicles using SVM and HOG\n",
    "\n",
    "### Outline:\n",
    "    0. Imports\n",
    "    1. Global configration\n",
    "    2. loading images \n",
    "    3. extract color histogram features\n",
    "    4. HOG features and CVTCOLOR\n",
    "    5. Get Feature Function\n",
    "    6. build dataset\n",
    "    7. gets dataset\n",
    "    8. load_scaler & train & test & load ,save_model\n",
    "    9. build_window_list\n",
    "    10. draw_bbox , get_sub_images , is_car Functions\n",
    "    11. window_search , multiscale_window_search\n",
    "    12. fast_frame_search\n",
    "    13. build_heatmap , threshold_heat , search_vehicles\n",
    "    14. labels_to_bboxes\n",
    "    15. processing output video\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from glob import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_CONFIG = {'SAMPLE_SZ':(64,64) ,\n",
    "          'COLORSPACE':'YCrCb',\n",
    "          'SPATIAL_BIN_SZ':(16,16),\n",
    "          'COLOR_BINS':32,\n",
    "          'COLOR_VAL_RANGE':(0,256),\n",
    "          'HOG_CHANNEL':'ALL',\n",
    "          'HOG_ORIENTS':9,\n",
    "          'HOG_PIX_PER_CELL':16,\n",
    "          'HOG_CELLS_PER_BLOCK':1,\n",
    "          'CELLS_PER_STEP':2,\n",
    "          'FRAME_HIST_COUNT':15,\n",
    "          'HEAT_THRESH':6,\n",
    "          'ROIS':[[(0,1280),(400,700)],[(640,1280),(400,650)],[(900,1280),(400,650)]],\n",
    "          'SCALES': [1.5,2,2.5],\n",
    "          'PREDICTION_THRESH':0.7\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. loading images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgread(path):\n",
    "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_image_data(paths):\n",
    "    data = []\n",
    "    for path in paths:\n",
    "        img_data = imgread(path)\n",
    "        data.append(img_data)\n",
    "    return np.array(data,dtype=np.uint8)\n",
    "\n",
    "\n",
    "def extract_spatial_bin_features(img,size):\n",
    "          \n",
    "    return cv2.resize(img,size).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. extract color histogram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_hist_features(img,nbins,range_vals):\n",
    "    chan0_hist = np.histogram(img[:,:,0],bins=nbins,range=range_vals)\n",
    "    chan1_hist = np.histogram(img[:,:,1],bins=nbins,range=range_vals)\n",
    "    chan2_hist = np.histogram(img[:,:,2],bins=nbins,range=range_vals)\n",
    "    \n",
    "    color_hist_features = np.concatenate((chan0_hist[0],\n",
    "                                         chan1_hist[0],\n",
    "                                         chan2_hist[0]))\n",
    "    return color_hist_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HOG features and CVTCOLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img_channel,nb_orient, \n",
    "                         nb_pix_per_cell,\n",
    "                         nb_cell_per_block, \n",
    "                         visualize= False, \n",
    "                         ret_vector=True):\n",
    "    \n",
    "    if visualize == True:\n",
    "        features, hog_image = hog(img_channel,orientations=nb_orient,\n",
    "                                  pixels_per_cell= (nb_pix_per_cell,nb_pix_per_cell),\n",
    "                                  cells_per_block = (nb_cell_per_block,nb_cell_per_block),\n",
    "                                  visualize=True,\n",
    "                                  feature_vector=ret_vector)\n",
    "        return features, hog_image\n",
    "    \n",
    "    else:\n",
    "        features  = hog(img_channel,orientations=nb_orient,\n",
    "                                  pixels_per_cell = (nb_pix_per_cell,nb_pix_per_cell),\n",
    "                                  cells_per_block = (nb_cell_per_block,nb_cell_per_block),\n",
    "                                  visualize=False,\n",
    "                                  feature_vector=ret_vector)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "def cvtColor(img,colorspace:str):\n",
    "    if colorspace == 'HSV':\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "    elif colorspace == 'HLS':\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "            \n",
    "    elif colorspace == 'LUV':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        \n",
    "    elif colorspace == 'YUV':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "    elif colorspace == 'YCrCb':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "            \n",
    "    else:\n",
    "        raise Exception(\"% colorspace is not a valid colorspace\"%(colorspace))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img,hog_channel,colorspace):\n",
    "    \n",
    "    if colorspace != 'RGB':\n",
    "        img = cvtColor(img,colorspace)\n",
    "        \n",
    "            \n",
    "    spatial_bin_features = \\\n",
    "    extract_spatial_bin_features(img,size =  GLOBAL_CONFIG['SPATIAL_BIN_SZ'])\n",
    "    \n",
    "    color_hist_features  = \\\n",
    "    extract_color_hist_features(img,\n",
    "                                nbins=GLOBAL_CONFIG['COLOR_BINS'],\n",
    "                                range_vals=GLOBAL_CONFIG['COLOR_VAL_RANGE'])\n",
    "    \n",
    "    if hog_channel == 'ALL':\n",
    "        hog_features = [ ]\n",
    "        \n",
    "        for channel in range(3):\n",
    "            hog_features.append(\n",
    "                    extract_hog_features(\n",
    "                            img[:,:,channel],\n",
    "                            nb_orient=GLOBAL_CONFIG['HOG_ORIENTS'],\n",
    "                            nb_pix_per_cell=GLOBAL_CONFIG['HOG_PIX_PER_CELL'],\n",
    "                            nb_cell_per_block = GLOBAL_CONFIG['HOG_CELLS_PER_BLOCK']))\n",
    "            \n",
    "        hog_features = np.ravel(hog_features)\n",
    "    \n",
    "    else:\n",
    "        hog_features = extract_hog_features(img[:,:,hog_channel],\n",
    "                            nb_orient=GLOBAL_CONFIG['HOG_ORIENTS'],\n",
    "                            nb_pix_per_cell=GLOBAL_CONFIG['HOG_PIX_PER_CELL'],\n",
    "                            nb_cell_per_block = GLOBAL_CONFIG['HOG_CELLS_PER_BLOCK'])\n",
    "    \n",
    "    return np.concatenate((spatial_bin_features,\n",
    "                          color_hist_features,\n",
    "                          hog_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(car_paths,notcar_paths):\n",
    "    paths = car_paths+notcar_paths\n",
    "    \n",
    "    X = []\n",
    "    for path in tqdm(paths):\n",
    "        img = imgread(path)\n",
    "        X.append(get_features(img,\n",
    "                              hog_channel= GLOBAL_CONFIG['HOG_CHANNEL'],\n",
    "                              colorspace=GLOBAL_CONFIG['COLORSPACE']))\n",
    "        \n",
    "    X = np.reshape(X,[len(paths),-1])\n",
    "    \n",
    "    \n",
    "    y = np.concatenate((np.ones(len(car_paths)),\n",
    "                       np.zeros(len(notcar_paths))))\n",
    "    \n",
    "    \n",
    "    Scaler_X = StandardScaler().fit(X)    \n",
    "    \n",
    "    X_scaled = Scaler_X.transform(X)\n",
    "    \n",
    "    X_scaled, y = shuffle(X_scaled,y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_scaled,y,train_size=0.7)\n",
    "        \n",
    "    del([X_scaled,y])\n",
    "    \n",
    "    with open('train.p','wb') as f:\n",
    "        train_set = {'data':X_train, 'labels':y_train}\n",
    "        pickle.dump(train_set,f)\n",
    "        \n",
    "    with open('test.p','wb') as f:\n",
    "        test_set = {'data':X_test, 'labels':y_test}\n",
    "        pickle.dump(test_set,f)\n",
    "    \n",
    "    with open('scaler.p','wb') as f:\n",
    "        pickle.dump(Scaler_X,f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(force=False):\n",
    "    \n",
    "    if (force == True)\\\n",
    "    or not os.path.isfile('train.p')\\\n",
    "    or not os.path.isfile('test.p'):\n",
    "            \n",
    "        # Load all image data.\n",
    "        vehicle_img_path = []\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_Far/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_Left/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_MiddleClose/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_Right/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/KITTI_extracted/*.png'))\n",
    "          \n",
    "        non_vehicle_img_path = []\n",
    "        non_vehicle_img_path.extend(glob('non-vehicles/Extras/*.png'))\n",
    "        non_vehicle_img_path.extend(glob('non-vehicles/GTI/*.png'))\n",
    "        \n",
    "        build_datasets(vehicle_img_path, non_vehicle_img_path)\n",
    "        \n",
    "    with open('train.p','rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "        \n",
    "    with open('test.p','rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "        \n",
    "    return (train_data,test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def load_scaler(filename):\n",
    "    with open(filename,'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "        return scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(X,y):\n",
    "    hyperparams = {'C':[0.1,1,10],\n",
    "                   'kernel':['linear']}\n",
    "    svc = SVC(probability=True)\n",
    "    clf = GridSearchCV(svc,hyperparams,verbose=2)\n",
    "    clf.fit(X,y)\n",
    "    return clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model,X,y):\n",
    "    return round(model.score(X,y), 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model,filename):\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "def load_model(filename):\n",
    "    with open(filename,'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Build window List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_window_list(x_range:tuple, y_range:tuple,\n",
    "                      wndw_sz:tuple, stride:tuple):\n",
    "    \n",
    "    wndw_width, wndw_height = wndw_sz[0], wndw_sz[1] \n",
    "    \n",
    "    x_start = x_range[0]\n",
    "    x_stop  = x_range[1] - (wndw_width-1)\n",
    "    \n",
    "    y_start = y_range[0] \n",
    "    y_stop  = y_range[1] - (wndw_height-1)\n",
    "    \n",
    "    x_stride, y_stride = stride[0], stride[1]\n",
    "    \n",
    "    \n",
    "    # Inclusive range.\n",
    "    def irange(start,stop,stride):\n",
    "        return range(start,stop+1,stride)\n",
    "    \n",
    "    x_start_pos = irange(x_start,x_stop,x_stride)\n",
    "    y_start_pos = irange(y_start,y_stop,y_stride)\n",
    "    \n",
    "    \n",
    "    for y_top in y_start_pos:\n",
    "        y_bottom = y_top + wndw_height -1\n",
    "        \n",
    "        for x_left in x_start_pos:\n",
    "            x_right = x_left + wndw_width - 1\n",
    "            \n",
    "            yield [(x_left,y_top),(x_right,y_bottom)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. draw_bbox , get_sub_images , is_car functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img,bboxes,color=[0,0,255],thick=5):\n",
    "    imgcpy = np.copy(img)\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(imgcpy,bbox[0],bbox[1],color,thick)\n",
    "    \n",
    "    return imgcpy\n",
    "\n",
    "\n",
    "def get_sub_images(img,wndw_sz:tuple,stride:tuple,resize=None):\n",
    "    x_range = (0,img.shape[1]-1)\n",
    "    y_range = (0,img.shape[0]-1)\n",
    "    \n",
    "    wndw_list = build_window_list(x_range,y_range,wndw_sz,stride)\n",
    "    \n",
    "    for wndw in wndw_list:\n",
    "        xl,xr = wndw[0][0], wndw[1][0] + 1\n",
    "        yl,yr = wndw[0][1], wndw[1][1] + 1\n",
    "        \n",
    "        if resize != None:\n",
    "            sub_image = cv2.resize(img[yl:yr, xl:xr],resize)\n",
    "        else:\n",
    "            sub_image = img[yl:yr, xl:xr]\n",
    "        \n",
    "        yield (sub_image,wndw)\n",
    "        \n",
    "        \n",
    "def is_car(model,features):\n",
    "     prediction_probs = model.predict_proba(features).flatten()\n",
    "     return prediction_probs[1] > GLOBAL_CONFIG['PREDICTION_THRESH']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
