{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce76a4d",
   "metadata": {},
   "source": [
    "# Vehicle Detection\n",
    "\n",
    "### Detecting vehicles using SVM and HOG\n",
    "\n",
    "### Outline:\n",
    "    0. Imports\n",
    "    1. Global configration\n",
    "    2. loading images \n",
    "    3. extract color histogram features\n",
    "    4. HOG features and CVTCOLOR\n",
    "    5. Get Feature Function\n",
    "    6. build dataset\n",
    "    7. gets dataset\n",
    "    8. load_scaler & train & test & load ,save_model\n",
    "    9. build_window_list\n",
    "    10. draw_bbox , get_sub_images , is_car Functions\n",
    "    11. window_search , multiscale_window_search\n",
    "    12. fast_frame_search\n",
    "    13. build_heatmap , threshold_heat , search_vehicles\n",
    "    14. labels_to_bboxes\n",
    "    15. processing output video\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe503d45",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1ebe29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from glob import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26565aa",
   "metadata": {},
   "source": [
    "## 1. Global configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f8529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_CONFIG = {'SAMPLE_SZ':(64,64) ,\n",
    "          'COLORSPACE':'YCrCb',\n",
    "          'SPATIAL_BIN_SZ':(16,16),\n",
    "          'COLOR_BINS':32,\n",
    "          'COLOR_VAL_RANGE':(0,256),\n",
    "          'HOG_CHANNEL':'ALL',\n",
    "          'HOG_ORIENTS':9,\n",
    "          'HOG_PIX_PER_CELL':16,\n",
    "          'HOG_CELLS_PER_BLOCK':1,\n",
    "          'CELLS_PER_STEP':2,\n",
    "          'FRAME_HIST_COUNT':15,\n",
    "          'HEAT_THRESH':6,\n",
    "          'ROIS':[[(0,1280),(400,700)],[(640,1280),(400,650)],[(900,1280),(400,650)]],\n",
    "          'SCALES': [1.5,2,2.5],\n",
    "          'PREDICTION_THRESH':0.7\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b6ec9",
   "metadata": {},
   "source": [
    "## 2. loading images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25287454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgread(path):\n",
    "    return cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def load_image_data(paths):\n",
    "    data = []\n",
    "    for path in paths:\n",
    "        img_data = imgread(path)\n",
    "        data.append(img_data)\n",
    "    return np.array(data,dtype=np.uint8)\n",
    "\n",
    "\n",
    "def extract_spatial_bin_features(img,size):\n",
    "          \n",
    "    return cv2.resize(img,size).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1d1617",
   "metadata": {},
   "source": [
    "## 3. extract color histogram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f767964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_hist_features(img,nbins,range_vals):\n",
    "    chan0_hist = np.histogram(img[:,:,0],bins=nbins,range=range_vals)\n",
    "    chan1_hist = np.histogram(img[:,:,1],bins=nbins,range=range_vals)\n",
    "    chan2_hist = np.histogram(img[:,:,2],bins=nbins,range=range_vals)\n",
    "    \n",
    "    color_hist_features = np.concatenate((chan0_hist[0],\n",
    "                                         chan1_hist[0],\n",
    "                                         chan2_hist[0]))\n",
    "    return color_hist_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ede73",
   "metadata": {},
   "source": [
    "## 4. HOG features and CVTCOLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4687bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img_channel,nb_orient, \n",
    "                         nb_pix_per_cell,\n",
    "                         nb_cell_per_block, \n",
    "                         visualize= False, \n",
    "                         ret_vector=True):\n",
    "    \n",
    "    if visualize == True:\n",
    "        features, hog_image = hog(img_channel,orientations=nb_orient,\n",
    "                                  pixels_per_cell= (nb_pix_per_cell,nb_pix_per_cell),\n",
    "                                  cells_per_block = (nb_cell_per_block,nb_cell_per_block),\n",
    "                                  visualize=True,\n",
    "                                  feature_vector=ret_vector)\n",
    "        return features, hog_image\n",
    "    \n",
    "    else:\n",
    "        features  = hog(img_channel,orientations=nb_orient,\n",
    "                                  pixels_per_cell = (nb_pix_per_cell,nb_pix_per_cell),\n",
    "                                  cells_per_block = (nb_cell_per_block,nb_cell_per_block),\n",
    "                                  visualize=False,\n",
    "                                  feature_vector=ret_vector)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "def cvtColor(img,colorspace:str):\n",
    "    if colorspace == 'HSV':\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "    elif colorspace == 'HLS':\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "            \n",
    "    elif colorspace == 'LUV':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        \n",
    "    elif colorspace == 'YUV':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    \n",
    "    elif colorspace == 'YCrCb':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "            \n",
    "    else:\n",
    "        raise Exception(\"% colorspace is not a valid colorspace\"%(colorspace))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12053b",
   "metadata": {},
   "source": [
    "## 5. Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8498916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(img,hog_channel,colorspace):\n",
    "    \n",
    "    if colorspace != 'RGB':\n",
    "        img = cvtColor(img,colorspace)\n",
    "        \n",
    "            \n",
    "    spatial_bin_features = \\\n",
    "    extract_spatial_bin_features(img,size =  GLOBAL_CONFIG['SPATIAL_BIN_SZ'])\n",
    "    \n",
    "    color_hist_features  = \\\n",
    "    extract_color_hist_features(img,\n",
    "                                nbins=GLOBAL_CONFIG['COLOR_BINS'],\n",
    "                                range_vals=GLOBAL_CONFIG['COLOR_VAL_RANGE'])\n",
    "    \n",
    "    if hog_channel == 'ALL':\n",
    "        hog_features = [ ]\n",
    "        \n",
    "        for channel in range(3):\n",
    "            hog_features.append(\n",
    "                    extract_hog_features(\n",
    "                            img[:,:,channel],\n",
    "                            nb_orient=GLOBAL_CONFIG['HOG_ORIENTS'],\n",
    "                            nb_pix_per_cell=GLOBAL_CONFIG['HOG_PIX_PER_CELL'],\n",
    "                            nb_cell_per_block = GLOBAL_CONFIG['HOG_CELLS_PER_BLOCK']))\n",
    "            \n",
    "        hog_features = np.ravel(hog_features)\n",
    "    \n",
    "    else:\n",
    "        hog_features = extract_hog_features(img[:,:,hog_channel],\n",
    "                            nb_orient=GLOBAL_CONFIG['HOG_ORIENTS'],\n",
    "                            nb_pix_per_cell=GLOBAL_CONFIG['HOG_PIX_PER_CELL'],\n",
    "                            nb_cell_per_block = GLOBAL_CONFIG['HOG_CELLS_PER_BLOCK'])\n",
    "    \n",
    "    return np.concatenate((spatial_bin_features,\n",
    "                          color_hist_features,\n",
    "                          hog_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07fa69",
   "metadata": {},
   "source": [
    "# 6. Build dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e596013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(car_paths,notcar_paths):\n",
    "    paths = car_paths+notcar_paths\n",
    "    \n",
    "    X = []\n",
    "    for path in tqdm(paths):\n",
    "        img = imgread(path)\n",
    "        X.append(get_features(img,\n",
    "                              hog_channel= GLOBAL_CONFIG['HOG_CHANNEL'],\n",
    "                              colorspace=GLOBAL_CONFIG['COLORSPACE']))\n",
    "        \n",
    "    X = np.reshape(X,[len(paths),-1])\n",
    "    \n",
    "    \n",
    "    y = np.concatenate((np.ones(len(car_paths)),\n",
    "                       np.zeros(len(notcar_paths))))\n",
    "    \n",
    "    \n",
    "    Scaler_X = StandardScaler().fit(X)    \n",
    "    \n",
    "    X_scaled = Scaler_X.transform(X)\n",
    "    \n",
    "    X_scaled, y = shuffle(X_scaled,y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_scaled,y,train_size=0.7)\n",
    "        \n",
    "    del([X_scaled,y])\n",
    "    \n",
    "    with open('train.p','wb') as f:\n",
    "        train_set = {'data':X_train, 'labels':y_train}\n",
    "        pickle.dump(train_set,f)\n",
    "        \n",
    "    with open('test.p','wb') as f:\n",
    "        test_set = {'data':X_test, 'labels':y_test}\n",
    "        pickle.dump(test_set,f)\n",
    "    \n",
    "    with open('scaler.p','wb') as f:\n",
    "        pickle.dump(Scaler_X,f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e264dc4",
   "metadata": {},
   "source": [
    "## 7. Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df399743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(force=False):\n",
    "    \n",
    "    if (force == True)\\\n",
    "    or not os.path.isfile('train.p')\\\n",
    "    or not os.path.isfile('test.p'):\n",
    "            \n",
    "        # Load all image data.\n",
    "        vehicle_img_path = []\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_Far/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_Left/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_MiddleClose/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/GTI_Right/*.png'))\n",
    "        vehicle_img_path.extend(glob('vehicles/KITTI_extracted/*.png'))\n",
    "          \n",
    "        non_vehicle_img_path = []\n",
    "        non_vehicle_img_path.extend(glob('non-vehicles/Extras/*.png'))\n",
    "        non_vehicle_img_path.extend(glob('non-vehicles/GTI/*.png'))\n",
    "        \n",
    "        build_datasets(vehicle_img_path, non_vehicle_img_path)\n",
    "        \n",
    "    with open('train.p','rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "        \n",
    "    with open('test.p','rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "        \n",
    "    return (train_data,test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dca507",
   "metadata": {},
   "source": [
    "## 8. Load Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e52f56",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_14556/1205234587.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\RENAD\\AppData\\Local\\Temp/ipykernel_14556/1205234587.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    with open(filename,'rb') as f:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    def load_scaler(filename):\n",
    "    with open(filename,'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "        return scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efb70f",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d52d8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(X,y):\n",
    "    hyperparams = {'C':[0.1,1,10],\n",
    "                   'kernel':['linear']}\n",
    "    svc = SVC(probability=True)\n",
    "    clf = GridSearchCV(svc,hyperparams,verbose=2)\n",
    "    clf.fit(X,y)\n",
    "    return clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8947b",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105771cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model,X,y):\n",
    "    return round(model.score(X,y), 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc8a2b",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model,filename):\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b77c11",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11429c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "def load_model(filename):\n",
    "    with open(filename,'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132a253",
   "metadata": {},
   "source": [
    "## 9. Build window List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_window_list(x_range:tuple, y_range:tuple,\n",
    "                      wndw_sz:tuple, stride:tuple):\n",
    "    \n",
    "    wndw_width, wndw_height = wndw_sz[0], wndw_sz[1] \n",
    "    \n",
    "    x_start = x_range[0]\n",
    "    x_stop  = x_range[1] - (wndw_width-1)\n",
    "    \n",
    "    y_start = y_range[0] \n",
    "    y_stop  = y_range[1] - (wndw_height-1)\n",
    "    \n",
    "    x_stride, y_stride = stride[0], stride[1]\n",
    "    \n",
    "    \n",
    "    # Inclusive range.\n",
    "    def irange(start,stop,stride):\n",
    "        return range(start,stop+1,stride)\n",
    "    \n",
    "    x_start_pos = irange(x_start,x_stop,x_stride)\n",
    "    y_start_pos = irange(y_start,y_stop,y_stride)\n",
    "    \n",
    "    \n",
    "    for y_top in y_start_pos:\n",
    "        y_bottom = y_top + wndw_height -1\n",
    "        \n",
    "        for x_left in x_start_pos:\n",
    "            x_right = x_left + wndw_width - 1\n",
    "            \n",
    "            yield [(x_left,y_top),(x_right,y_bottom)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bab044",
   "metadata": {},
   "source": [
    "## 10. draw_bbox , get_sub_images , is_car functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fffa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img,bboxes,color=[0,0,255],thick=5):\n",
    "    imgcpy = np.copy(img)\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(imgcpy,bbox[0],bbox[1],color,thick)\n",
    "    \n",
    "    return imgcpy\n",
    "\n",
    "\n",
    "def get_sub_images(img,wndw_sz:tuple,stride:tuple,resize=None):\n",
    "    x_range = (0,img.shape[1]-1)\n",
    "    y_range = (0,img.shape[0]-1)\n",
    "    \n",
    "    wndw_list = build_window_list(x_range,y_range,wndw_sz,stride)\n",
    "    \n",
    "    for wndw in wndw_list:\n",
    "        xl,xr = wndw[0][0], wndw[1][0] + 1\n",
    "        yl,yr = wndw[0][1], wndw[1][1] + 1\n",
    "        \n",
    "        if resize != None:\n",
    "            sub_image = cv2.resize(img[yl:yr, xl:xr],resize)\n",
    "        else:\n",
    "            sub_image = img[yl:yr, xl:xr]\n",
    "        \n",
    "        yield (sub_image,wndw)\n",
    "        \n",
    "        \n",
    "def is_car(model,features):\n",
    "     prediction_probs = model.predict_proba(features).flatten()\n",
    "     return prediction_probs[1] > GLOBAL_CONFIG['PREDICTION_THRESH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77fbcd",
   "metadata": {},
   "source": [
    "# 11. window_search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23615292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_search(img,wndw_sz:tuple,stride:tuple,model,scaler):\n",
    "\n",
    "    sub_images = get_sub_images(img,wndw_sz,stride,resize=GLOBAL_CONFIG['SAMPLE_SZ'])\n",
    "    \n",
    "    for sub_image,wndw in sub_images:\n",
    "        features = get_features(sub_image,hog_channel= GLOBAL_CONFIG['HOG_CHANNEL'],\n",
    "                              colorspace=GLOBAL_CONFIG['COLORSPACE'])\n",
    "        scaled_features = scaler.transform(features.reshape(1,-1))\n",
    "        \n",
    "        car = is_car(model,scaled_features)\n",
    "        \n",
    "        if car == 1:\n",
    "            yield wndw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f83804",
   "metadata": {},
   "source": [
    "# 11. multiscale_window_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e93363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale_window_search(img,wndw_sz_list,strides_list,model,scaler):\n",
    "       \n",
    "    for i in range(len(wndw_sz_list)):\n",
    "        windows = window_search(img,wndw_sz_list[i],strides_list[i],\n",
    "                                model,scaler)\n",
    "        for window in windows:\n",
    "            yield window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf78631",
   "metadata": {},
   "source": [
    "## 12. Fast_Frame_Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast_frame_search\n",
    "def fast_frame_search(img,x_left,x_rght,y_top,y_bot,scale,model,scaler):\n",
    "    ''' \n",
    "    Perfrom fast search for vehicles across a single video\n",
    "    frame.\n",
    "    '''\n",
    "      \n",
    "    # Convert colorspace if needed.\n",
    "    if GLOBAL_CONFIG['COLORSPACE'] != 'RGB':\n",
    "        img = cvtColor(img,GLOBAL_CONFIG['COLORSPACE'])\n",
    "    \n",
    "    # Extract region-of-interest(ROI).    \n",
    "    img_roi = img[y_top:y_bot,x_left:x_rght,:]\n",
    "    \n",
    "    # Scale image if needed.\n",
    "    if scale != 1:\n",
    "        target_width = np.int(img_roi.shape[1]/scale)\n",
    "        target_height = np.int(img_roi.shape[0]/scale)\n",
    "        img_roi = cv2.resize(img_roi,(target_width,target_height))\n",
    "        \n",
    "    # Find HOG feature(s) for the entire ROI.\n",
    "    hog_roi = []\n",
    "    \n",
    "    channel_ids = [0,1,2] if GLOBAL_CONFIG['HOG_CHANNEL'] == 'ALL' \\\n",
    "    else [GLOBAL_CONFIG['HOG_CHANNEL']]\n",
    "    \n",
    "    for channel_id in channel_ids:\n",
    "        hog_chann = extract_hog_features(img_roi[:,:,channel_id],\n",
    "                     nb_orient=GLOBAL_CONFIG['HOG_ORIENTS'],\n",
    "                     nb_pix_per_cell=GLOBAL_CONFIG['HOG_PIX_PER_CELL'],\n",
    "                     nb_cell_per_block = GLOBAL_CONFIG['HOG_CELLS_PER_BLOCK'],\n",
    "                     ret_vector=False)\n",
    "        hog_roi.append(hog_chann)            \n",
    "\n",
    " # Calculate sliding window parameters.\n",
    "    pix_per_cell = GLOBAL_CONFIG['HOG_PIX_PER_CELL']\n",
    "    cells_per_block = GLOBAL_CONFIG['HOG_CELLS_PER_BLOCK']\n",
    "    \n",
    "    nb_cells_x = (img_roi.shape[1] // pix_per_cell)\n",
    "    nb_blocks_x = nb_cells_x - (cells_per_block-1)\n",
    "    \n",
    "    nb_cells_y = (img_roi.shape[0] // pix_per_cell)\n",
    "    nb_blocks_y = nb_cells_y - (cells_per_block-1)\n",
    "    \n",
    "    wndw_sz = GLOBAL_CONFIG['SAMPLE_SZ'][0]\n",
    "    blocks_per_window = (wndw_sz // pix_per_cell) - (cells_per_block-1)\n",
    "    \n",
    "    cells_per_step = int(GLOBAL_CONFIG['CELLS_PER_STEP'])\n",
    "    \n",
    "    nb_steps_x = (nb_blocks_x - blocks_per_window ) // cells_per_step + 1\n",
    "    nb_steps_y = (nb_blocks_y - blocks_per_window ) // cells_per_step + 1\n",
    "    \n",
    "    if nb_steps_x <= 0  or nb_steps_y <= 0:\n",
    "        print('Warning: Using scale {} will generate no sliding windows'.format(scale))\n",
    "    \n",
    "    for step_y in range(nb_steps_y):\n",
    "        for step_x in range(nb_steps_x):\n",
    "            \n",
    "            cell_x = step_x * cells_per_step\n",
    "            cell_y = step_y * cells_per_step\n",
    "            \n",
    "            hog_features = np.empty([0])\n",
    "            \n",
    "            for channel_id in channel_ids:\n",
    "                hog_chann = hog_roi[channel_id]\n",
    "                hog_vector = hog_chann[ cell_y:cell_y+blocks_per_window,cell_x:cell_x+blocks_per_window].flatten()\n",
    "                hog_features = np.hstack((hog_features,hog_vector))\n",
    "                \n",
    "                \n",
    "            xleft_px = cell_x * pix_per_cell\n",
    "            ytop_px  = cell_y * pix_per_cell\n",
    "\n",
    "            \n",
    "            # Extract sub image\n",
    "            sub_img = img_roi[ytop_px:ytop_px+wndw_sz, xleft_px:xleft_px+wndw_sz]\n",
    "            \n",
    "            spatial_features = extract_spatial_bin_features(sub_img,GLOBAL_CONFIG['SPATIAL_BIN_SZ'])\n",
    "            hist_features    = extract_color_hist_features(sub_img,\n",
    "                                                           GLOBAL_CONFIG['COLOR_BINS'],\n",
    "                                                           GLOBAL_CONFIG['COLOR_VAL_RANGE'])\n",
    "            \n",
    "            feature_vector = np.hstack((spatial_features,hist_features,hog_features))\n",
    "            \n",
    "            scaled_features = scaler.transform(feature_vector.reshape([1,-1]))\n",
    "            \n",
    "            if is_car(model,scaled_features):\n",
    "                \n",
    "                bbox_x_left = np.int(xleft_px*scale)\n",
    "                bbox_y_top  = np.int(ytop_px*scale)\n",
    "                \n",
    "                bbox_sz = np.int(wndw_sz*scale)\n",
    "                \n",
    "                yield [(bbox_x_left+x_left, bbox_y_top+y_top),(bbox_x_left+x_left+bbox_sz, bbox_y_top+y_top+bbox_sz)]\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
